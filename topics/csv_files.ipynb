{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"http://www2.le.ac.uk/liscb1.jpg\">  \n",
    "# Leicester Institute of Structural and Chemical Biology: Python for Biochemists\n",
    "# Reading and Writing CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most common ways that data are stored is as Comma Separated Values (csv) files.  CSV files have many advanteages over other types - the two most important are:  \n",
    "1. They are human readable, so if you need to get the data back in 10 years any software can do it (unlike formats such as .xls)\n",
    "2. They can be as large as you like (unlike formats such as .xls)\n",
    "\n",
    "... and they also have one big disadvantage: for the amount of data they store, they take up a lot of space.  By the time the files get so big that you may have trouble storing them, you'll probably have problems with computer RAM as well.  \n",
    "\n",
    "While there are many ways to read and write these, the three most common are presented below.  You should choose which to use based on what you're going to do with the data once you have it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Standard Library  \n",
    "This method works for all data, and doesn't use any external libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing data  \n",
    "Although we're probabaly going to read data more often than write, it's easier to write the data as we're in total control.  We'll start with some imports and creating some test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "test_column_names = ['Column 1', 'Column B', 3]\n",
    "test_data = [1, 2, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there are so many different ways to read and write CSV files, python uses `readers` and `writers`.  The simple example should be sufficient for most cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../tmp/psl_csv_file_default.csv', mode='w') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(test_column_names)\n",
    "    csv_writer.writerow(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can 'cat' the file using a *notebook magic* to see what actually got written:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 1,Column B,3\r",
      "\r\n",
      "1,2,7\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "%cat ../tmp/psl_csv_file_default.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to have more quotes or different delimeters, these are all possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Column 1\";\"Column B\";3\r",
      "\r\n",
      "1;2;7\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "with open('../tmp/psl_csv_file_fancy.csv', mode='w') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=';', quotechar='\"', quoting=csv.QUOTE_NONNUMERIC)\n",
    "    csv_writer.writerow(test_column_names)\n",
    "    csv_writer.writerow(test_data)\n",
    "\n",
    "%cat ../tmp/psl_csv_file_fancy.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write tab-separated values (tsv) if we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 1\tColumn B\t3\r",
      "\r\n",
      "1\t2\t7\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "with open('../tmp/psl_tsv_file.tsv', mode='w') as tsv_file:\n",
    "    tsv_writer = csv.writer(tsv_file, delimiter='\\t')  # \\t is the escape character for tab\n",
    "    tsv_writer.writerow(test_column_names)\n",
    "    tsv_writer.writerow(test_data)\n",
    "\n",
    "%cat ../tmp/psl_tsv_file.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even write white-space-separated if we want (note how the writer automatically handles qoutes for us):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Column 1\" \"Column B\" 3\r",
      "\r\n",
      "1 2 7\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "with open('../tmp/psl_wssv_file.csv', mode='w') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=' ')\n",
    "    csv_writer.writerow(test_column_names)\n",
    "    csv_writer.writerow(test_data)\n",
    "\n",
    "%cat ../tmp/psl_wssv_file.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the writer just needs something to be 'file like', we can write directly to compressed files if we wish (note we have to be careful about how we open the file):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001f�\b\b3�|_\u0002�psl_csv_file.zip\u0000r��)��S0�q�0�t�y�\f",
      "u�t�y�\u0000\u0000\u0000\u0000��\u0003\u0000\u000b",
      "A\u0012�\u001c",
      "\u0000\u0000\u0000"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "with gzip.open('../tmp/psl_csv_file.zip', mode='wt') as zip_file:  # gzip defaults to binary data, so we use 'wt' for text\n",
    "    csv_writer = csv.writer(zip_file)\n",
    "    csv_writer.writerow(test_column_names)\n",
    "    csv_writer.writerow(test_data)\n",
    "\n",
    "%cat ../tmp/psl_csv_file.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use a mapping (like a dict) to create our csv files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 1,Column B,3\r",
      "\r\n",
      "1,2,7\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "data_dict = {'Column 1': 1,\n",
    "             'Column B': 2,\n",
    "             3: 7\n",
    "             }\n",
    "data = [data_dict,]\n",
    "\n",
    "with open('../tmp/psl_csv_file_from_dict.csv', mode='w') as csv_file:\n",
    "    csv_writer = csv.DictWriter(csv_file, fieldnames = data[0].keys())\n",
    "    \n",
    "    csv_writer.writeheader()\n",
    "    for item in data:\n",
    "        csv_writer.writerow(item)\n",
    "\n",
    "%cat ../tmp/psl_csv_file_from_dict.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be a bit dangerous, though - you have to make sure that all the dictionaries have the same keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dict contains fields not in fieldnames: 'Column C'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3c3f4e688973>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcsv_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mcsv_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../tmp/psl_csv_file_from_dict.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.7/csv.py\u001b[0m in \u001b[0;36mwriterow\u001b[0;34m(self, rowdict)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.7/csv.py\u001b[0m in \u001b[0;36m_dict_to_list\u001b[0;34m(self, rowdict)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrong_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 raise ValueError(\"dict contains fields not in fieldnames: \"\n\u001b[0;32m--> 151\u001b[0;31m                                  + \", \".join([repr(x) for x in wrong_fields]))\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrowdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: dict contains fields not in fieldnames: 'Column C'"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "data_dict_1 = {'Column 1': 1,\n",
    "               'Column B': 2,\n",
    "               3: 7\n",
    "               }\n",
    "data_dict_2 = {'Column 1': 1,\n",
    "               'Column C': 42\n",
    "               }\n",
    "data = [data_dict_1, data_dict_2]\n",
    "\n",
    "with open('../tmp/psl_csv_file_from_dict.csv', mode='w') as csv_file:\n",
    "    csv_writer = csv.DictWriter(csv_file, fieldnames = data[0].keys())\n",
    "    \n",
    "    csv_writer.writeheader()\n",
    "    for item in data:\n",
    "        csv_writer.writerow(item)\n",
    "\n",
    "%cat ../tmp/psl_csv_file_from_dict.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data\n",
    "#### List output\n",
    "As you'd expect, reading the data works similarly to how writing the data does - except in this case we need to know what the format is or we risk getting junk.  By Default, each row comes as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Column 1', 'Column B', '3']\n",
      "['1', '2', '7']\n"
     ]
    }
   ],
   "source": [
    "with open('../tmp/psl_csv_file_default.csv', mode='r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Column 1', 'Column B', 3.0]\n",
      "[1.0, 2.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "# semicolon-separated values\n",
    "with open('../tmp/psl_csv_file_fancy.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';', quotechar='\"', quoting=csv.QUOTE_NONNUMERIC)\n",
    "    for row in csv_reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that if you get the format wrong, you still get *something* out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Column 1;\"Column B\";3']\n",
      "['1;2;7']\n"
     ]
    }
   ],
   "source": [
    "# semicolon-separated values\n",
    "with open('../tmp/psl_csv_file_fancy.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Column 1', 'Column B', '3']\n",
      "['1', '2', '7']\n"
     ]
    }
   ],
   "source": [
    "# tab-separated values\n",
    "with open('../tmp/psl_tsv_file.tsv') as tsv_file:\n",
    "    tsv_reader = csv.reader(tsv_file, delimiter='\\t')  # \\t is the escape character for tab\n",
    "    for row in tsv_reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Column 1', 'Column B', '3']\n",
      "['1', '2', '7']\n"
     ]
    }
   ],
   "source": [
    "# space-separated values\n",
    "with open('../tmp/psl_wssv_file.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=' ')\n",
    "    for row in csv_reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Column 1', 'Column B', '3']\n",
      "['1', '2', '7']\n"
     ]
    }
   ],
   "source": [
    "# gziped file\n",
    "with gzip.open('../tmp/psl_csv_file.zip', mode='rt') as zip_file:  # use 'rt' to get text\n",
    "    csv_reader = csv.reader(zip_file)\n",
    "    for row in csv_reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dict output\n",
    "In the examples above, we'd have to interpret the first row as column headers ourselves.  It's also possible to read the csv files as dictionaries (this is often very convenient.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 1: 1\n",
      "Column B: 2\n",
      "3: 7\n"
     ]
    }
   ],
   "source": [
    "with open('../tmp/psl_csv_file_default.csv', mode='r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        for k, v in row.items():\n",
    "            print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing data\n",
    "Although we're probabaly going to read data more often than write, it's easier to write the data as we're in total control.  We'll start with some imports and creating some test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column 1</th>\n",
       "      <th>Column B</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column 1  Column B  3\n",
       "0         1         2  7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df  = pd.DataFrame([[1, 2, 7]], columns=['Column 1', 'Column B', 3])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important difference here is that pandas adds an index, which shows up in the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",Column 1,Column B,3\r\n",
      "0,1,2,7\r\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('../tmp/pd_csv_default.csv')\n",
    "\n",
    "%cat ../tmp/pd_csv_default.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we specify one of the columns as an index, it all works as we'd expect..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column B</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column 1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column B  3\n",
       "Column 1             \n",
       "1                2  7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame([[1, 2, 7]], columns=['Column 1', 'Column B', 3]).set_index('Column 1')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 1,Column B,3\r\n",
      "1,2,7\r\n"
     ]
    }
   ],
   "source": [
    "df2.to_csv('../tmp/pd2_csv_default.csv')\n",
    "\n",
    "%cat ../tmp/pd2_csv_default.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pandas` lets you do all the fancy formatting the `csv` module does - check the documentation if you need that.  Because `pandas` opens the file for you, if you want to use gzip compression, you have to specify that in the call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001f�\b\b:�|_\u0002�pd2_csv_default.csv\u0000r��)��S0�q�0�t��\f",
      "u�t̹\u0000\u0000\u0000\u0000��\u0003\u0000\u0004��h\u001a\u0000\u0000\u0000"
     ]
    }
   ],
   "source": [
    "df2.to_csv('../tmp/pd2_csv_default.csv.gz', compression='gzip')\n",
    "\n",
    "%cat ../tmp/pd2_csv_default.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data\n",
    "`Pandas` reads csv files as well as you'd expect.  Because it's expecting a table-like format, it will try to use the first row as headers.  It even automatically detects compressed files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column 1</th>\n",
       "      <th>Column B</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column 1  Column B  3\n",
       "0         1         2  7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../tmp/pd2_csv_default.csv.gz')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't know which column to use as the index, so you have to tell it (if you want an index column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column B</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column 1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column B  3\n",
       "Column 1             \n",
       "1                2  7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../tmp/pd2_csv_default.csv.gz', index_col='Column 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can turn off the automatic header detection if you like, which will then automatically generate header names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Column 1</td>\n",
       "      <td>Column B</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1  2\n",
       "0  Column 1  Column B  3\n",
       "1         1         2  7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../tmp/pd2_csv_default.csv.gz', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy  \n",
    "Like all numpy based work, this is only really appropriate if you're going to be doing array-based numerical computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing data\n",
    "Although we're probabaly going to read data more often than write, it's easier to write the data as we're in total control.  We'll start with some imports and creating some test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " array \n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      " has type int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([(1, 2, 3),\n",
    "              (4, 5, 6)])\n",
    "print(f' array \\n{a}\\n has type {a.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000000000000000000e+00 2.000000000000000000e+00 3.000000000000000000e+00\r\n",
      "4.000000000000000000e+00 5.000000000000000000e+00 6.000000000000000000e+00\r\n"
     ]
    }
   ],
   "source": [
    "np.savetxt('../tmp/np_csv_default.csv', a)\n",
    "\n",
    "%cat ../tmp/np_csv_same-dtype.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data, again, is just the opposite of writing.  `Numpy` has loads of options to read csv files with all sorts of different formats and data types - but if you're not reading numeric arrays, you should probably be using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " array \n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      " has type float64\n"
     ]
    }
   ],
   "source": [
    "b = np.loadtxt('../tmp/np_csv_default.csv')\n",
    "print(f' array \\n{b}\\n has type {b.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compressed Data\n",
    "Note that `numpy` can read and write compressed data, but only it's binary format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PK\u0003\u0004\u0014\u0000\u0000\u0000\b\u0000\u0000\u0000!\u0000�c�W\u0000\u0000\u0000�\u0000\u0000\u0000\t\u0000\u0014\u0000arr_0.npy\u0001\u0000\u0010\u0000�\u0000\u0000\u0000\u0000\u0000\u0000\u0000W\u0000\u0000\u0000\u0000\u0000\u0000\u0000��\u0017�\u001b\u0010��P�P���Z�\\�n��n�i������_TR��\u0017�_��\r\n",
      "\u0012wK�)N\u0005�\u0017g$\u0016�\u0002�\u001aF:\r\n",
      "ƚ:\r\n",
      "�\r\n",
      "d\u0003.F\u0006\b`���P�\u0005J�Bi6(\r",
      "\u0000PK\u0001\u0002\u0014\u0003\u0014\u0000\u0000\u0000\b\u0000\u0000\u0000!\u0000�c�W\u0000\u0000\u0000�\u0000\u0000\u0000\t\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000�\u0001\u0000\u0000\u0000\u0000arr_0.npyPK\u0005\u0006\u0000\u0000\u0000\u0000\u0001\u0000\u0001\u00007\u0000\u0000\u0000�\u0000\u0000\u0000\u0000\u0000"
     ]
    }
   ],
   "source": [
    "np.savez_compressed('../tmp/np_csv_default.npz', a)\n",
    "\n",
    "%cat ../tmp/np_csv_default.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "arrays = np.load('../tmp/np_csv_default.npz')\n",
    "for array_name in arrays.files:\n",
    "    print(arrays[array_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
